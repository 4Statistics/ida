<style>@import url(style.css);</style>

# 2.1. Import/Export

This section covers a few ways to read/write `CSV` and `TXT` data, as well as common proprietary formats.

## Opening a CSV file

## Downloading a CSV file

We are going to use the [Daily Kos Elections' presidential results by congressional district for the 2012 and 2008 elections](http://www.dailykos.com/story/2012/11/19/1163009/-Daily-Kos-Elections-presidential-results-by-congressional-district-for-the-2012-2008-elections?detail=hide), for which the data is accessible as a [Google spreadsheet](https://docs.google.com/spreadsheet/pub?key=0Av8O-dN2giY6dEFCOFZ4ZnlKS0x3M3Y0WHd5aWFDWkE&single=true&gid=0&output=html). The [Google Docs API documentation](http://code.google.com/apis/spreadsheets/) tells us that we can get the data in CSV format through a URL request that includes the identifier key of the spreadsheet and the format specification `output=csv`.

```{r dk_get1, message=FALSE}
# Load RCurl package.
library(RCurl)
# Store the address of the spreadsheet.
dk_link <- "https://docs.google.com/spreadsheet/pub?key=0Av8O-dN2giY6dEFCOFZ4ZnlKS0x3M3Y0WHd5aWFDWkE&output=csv"
```

We now need to get the data from that address, using the `RCurl` library to fetch the online spreadsheet from the `dk_link` object in which we stored the link. Note that the `getURL` command is in a conditional statement that avoids downloading the same file again and again if you already have it.

When the file is fetched from online, we convert the result, which is a large text file, to a proper CSV (comma-separated values) file. We specify that we do not want strings converted to factors, i.e. that we do not want a numeric structure for the text variables.

```{r dk_get2}
if (!file.exists("data/dailykos.csv")) {
  # Download the spreadsheet.
  dk_html <- getURL(dk_link)
  # Transform the result into a proper dataset, leaving text variables (strings) unchanged.
  dk_data <- read.csv(textConnection(dk_html), stringsAsFactors = FALSE)
  # Save local copy.
  write.csv(dk_data, file = "data/dailykos.csv")
} else {
  # Open local copy.
  dk_data <- read.csv("data/dailykos.csv")
}
```

We finally inspect the result by looking at the structure of the dataset with `str` and the first few rows of data with `head`.

```{r dk_get3}
# Have a look at the final result.
str(dk_data)
# List the first data rows.
head(dk_data)
```

## Other formats

The `Hmisc` and `foreign` packages do a wonderful job at converting datasets in proprietary formats.

Here's a simple example using Stata.

Here's another example using Excel. [The data](http://www.inflationtrends.com/data/Raw_data.xlsx) are about inflation trends in the United States, as [made available](http://www.reddit.com/r/datasets/comments/13ww5b/have_some_data_on_us_food_and_fuel_prices_median/) by user [data_junkie](http://www.reddit.com/user/data_junkie) at Reddit on the [/r/datasets](http://www.reddit.com/r/datasets/) channel. Check out Reddit if you don't know about it already.

Because the data are formatted as an Excel 2007 file (`.xlsx`), you will need to load the [xlsx](http://cran.r-project.org/web/packages/xlsx/) package for the next commands to work. You would usually export the file as a CSV if it's only a single file that you need to import; the method shown below is useful only for larger batch imports.

The import is done through the `read.xlsx` command, with the `header` option set to `FALSE` because the first row of the spreadsheet is not a header (it holds the first row of data, not the variable names). After checking on the import, we subset the `infl` data frame to columns 3 and 4 and rename them.

```{r xlsx1, message=FALSE}
# Load the package.
library(xlsx)
# Import the data.
if (file.exists("data/us_inflation.xlsx")) {
  # Open local copy.
  infl <- read.xlsx("data/us_inflation.xlsx","median_income", header = FALSE)
} else {
  print("Cannot find dataset, loading from web...")
  # Retrieve file.
  infl <- read.xlsx("http://www.inflationtrends.com/data/Raw_data.xlsx", header = FALSE)
  # Save local copy.
  write.xlsx(infl, file = "data/us_inflation.xlsx")
}
# Check the result.
str(infl)
# Subset to columns 3 to 4.
infl <- infl[3:4]
# Add column names.
names(infl) <- c("year","medinc")
```

Let's plot the data to take a look. All we have here is median income by year: a single time series. We use `ggplot2` to draw a quick plot as a [simple line](http://docs.ggplot2.org/current/geom_line.html). The command understands the first argument as the x-variable and the second one as the y-variable. The `data` and `geom` arguments do the rest of the job.

```{r xlsx2, message=FALSE}
# A quick plot.
qplot(year, medinc, data = infl, geom = "line")
```

The end of the series shows a punctuation (you guessed it: welcome to the subprime crisis). Let's focus on the most recent years, then.

```{r xlsx3}
# Check how far the series goes.
summary(infl$year)
# Plot the last twenty years.
qplot(year,medinc,data=subset(infl, year > 1992),geom="line")
```

Finally, since the series seems to increase exponentially, let's have a look at the logged series, where the y-axis uses a logarithmic scale.

```{r xlsx4}
# A quick plot with a log scale.
qplot(year,medinc,data=infl,geom="line",log="y")
```

