<style>@import url(style.css);</style>
[Introduction to Data Analysis](index.html "Course index")

# 7. Differences

From a practical perspective, data comes with two measurable dimensions. The first one pertains to the reliability of the variables: with social data, you are rarely looking something that justifies several decimals of precision. The second aspect of measurement lies with the magnitude of the relationships that it expresses, and whether differences and association reaches statistical significance.

We'll start straight away with a real-world example, using fertility rates, measured in average births per woman, and GDP per capita. We will cover issues of statistical confidence, power and inference, using a few bivariate significance tests (tests that measure associations between two variables). Most functions are available as base R commands.

```{r packages, message=FALSE, warning=FALSE}
# Load packages.
packages <- c("countrycode", "ggplot2", "reshape", "WDI")
packages <- lapply(packages, FUN = function(x) {
  if(!require(x, character.only = TRUE)) {
    install.packages(x)
    library(x, character.only = TRUE)
  }
})
```

# Measuring bivariate associations

The measures that we will use are from [World Bank Indicators][wb] and from United Nations official statistics. The code below shows a quick way to import them from the World Bank website. Despite these being reliable sources, fertility rates build on census and hospital infrastructures that are not reliable on a worldwide basis, and GDP per capita is often measured out of [poor numbers][jerven].

[wb]: http://data.worldbank.org/
[jerven]: http://mortenjerven.com/poornumbers/

```{r wdi-data}
# Target file.
file = "data/wdi.births.2005.txt"
# Download source.
if(!file.exists(file)) {
  message("Downloading the data...")
  # Using the WDI package.
  wdi <- WDI(indicator = c("SP.DYN.TFRT.IN", "NY.GDP.PCAP.CD"), start = 2005, end = 2005)
  # Save local copy.
  write.csv(wdi, file, row.names = FALSE)
}
# Load CSV file.
wdi <- read.csv(file)
# Check result.
str(wdi)
```

The second aspect is what most people understand by statistics: whether these entities associate to each other under a certain level of confidence. 

We'll cover that last aspect

```{r wdi-data-prepare}
wdi$iso3c <- countrycode(wdi$iso2c, "iso2c", "iso3c")
wdi$Continent <- countrycode(wdi$iso2c, "iso2c", "continent")
wdi <- na.omit(wdi)
```

```{r wdi-plot-codes-auto}
# Scatterplot of fertility and GDP per capita with country codes and continents.
qplot(data = wdi, y = SP.DYN.TFRT.IN, x = log(NY.GDP.PCAP.CD), 
      color = Continent, label = iso3c, size = I(4), geom = "text") +
  labs(y = "Fertility rate", x = "GDP per capita (log units)")
```

```{r wdi-plot-boxes, tidy = FALSE}
# Box plot of fertility rate by continent.
qplot(data = wdi,
      y = SP.DYN.TFRT.IN, x = reorder(Continent, SP.DYN.TFRT.IN, median), 
      color = Continent, geom = "boxplot") +
  labs(y = "Fertility rate", x = NULL) +
  theme(legend.position = "none")
```


The summary statistics that you calculate from your sample are generalizable to the whole population if you select a level of confidence and use the sample size to determine the margin of error of your measurements.

There is [more than one reason](https://solomonmessing.wordpress.com/2012/03/04/visualization-series-insight-from-cleveland-and-tufte-on-plotting-numeric-data-by-groups/) not to use bar plots or pie charts. One of them is that you might want to plot an estimate instead of a value, by showing the size of the standard error on the graph.

Here's an example of [confidence intervals][ci] that uses, as most of our work, `ggplot2` graphics.

[ci]: http://wiki.stdout.org/rcookbook/Graphs/Plotting%20means%20and%20error%20bars%20(ggplot2)/

More reliable standard errors can be obtained through bootstrap resampling.

__Bootstrap resampling__ is a way to run the same test over simulated data obtained through sampling among permutations of observations, to see whether the effect persists if we use only some of the data. It provides a further test of what we might interpret from the *t*-test, or any other statistical procedure available for bootstrapping.

Resampling happens through simulations (or "replications") of alternative samples.

__Simulation__ generally aims at adding various possible scenarios to a statistical test or model: randomness can be used to let the software compute a procedure over slightly different parameters, again and again, until we reach a satisfying number of possibles and consider their results altogether. 

We can [bootstrap the standard error](https://solomonmessing.wordpress.com/2011/11/26/putting-it-all-together-concise-code-to-make-dotplots-with-weighted-bootstrapped-standard-errors/) by measuring it over simulated samples.

## *t*-test

Here's a rough overview of the *t*-test.

The __*t*-test__ estimates whether the means of two groups differ, based on the size of the observed difference and on the size of the sample used. It uses the *t*-distribution to approach the normal distribution, and assumes that the groups are independent and identically distributed (i.e. of identical variance) to compute the *p*-value of the test.

The point of the test is to verify whether observable differences have statistical power.

At low sample size, there is a risk to accept as significant some differences that could be caused by __sampling error__. To test that possibility, we consider the probability of the __null hypothesis__ $H_0$, which states that the difference $\mu_1 - \mu_2$ is equal to 0. Rejecting $H_0$ while it is actually true is known as the Type I Error.

The converse error can be equally dangerous: accepting the absence of a difference while there is one, a Type II Error, is one of the risks of working with low-$N$ samples, because their low __statistical power__ threatens the validity of the test. Furthermore, no statistical test can account for pre-processing errors in the data itself.

Let's see, for instance, if support for democracy has increased since 1990.

<!-- Deploy the data from the QOG.
  http://wiki.stdout.org/rcookbook/Statistical%20analysis/t-test/ -->

## Tables

__Tables__ with Chi-squared tests and odds ratios.

__Bar plots__: beurkâ€¦ except for [mosaic bars](https://learnr.wordpress.com/2009/04/02/ggplot2-marimekko-replacement-overlapping-bars/), perhaps.

__Mosaic plots__: yay! See examples [here](https://learnr.wordpress.com/2009/03/29/ggplot2_marimekko_mosaic_chart/) and [there](http://is-r.tumblr.com/post/33290921643/simple-marimekko-mosaic-plots)). Definitely more appropriate to speak of modal groups, frequencies and fractions of a population.

> __Next__: [Confidence intervals](071_intervals.html).
